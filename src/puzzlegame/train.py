"""
è®­ç»ƒè„šæœ¬ï¼šä¸“é—¨ç”¨äºè§£å†³ AI å­¦ä¸ä¼šåœä¸‹çš„é—®é¢˜
ä½¿ç”¨æ–¹æ³•: python src/puzzlegame/train.py
"""
import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import DataLoader, TensorDataset

# --- ğŸ”§ è·¯å¾„ä¿®å¤ï¼šåŠ¨æ€è·å–é¡¹ç›®æ ¹ç›®å½• ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
sys.path.append(PROJECT_ROOT)

from puzzlegame.algorithms.behavioral_cloning import PuzzleNet

def train_bc_model():
    # ================= 1. è·¯å¾„é…ç½®ä¸æ•°æ®åŠ è½½ =================
    data_path = os.path.join(CURRENT_DIR, "data", "raw", "expert_demos.npz")
    
    if not os.path.exists(data_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {data_path}")
        print("è¯·å…ˆè¿è¡Œæ•°æ®æ”¶é›†è„šæœ¬ç”Ÿæˆ expert_demos.npz")
        return

    try:
        data = np.load(data_path)
        states = data['states']
        actions = data['actions']
        print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼Œæ ·æœ¬æ€»æ•°: {len(states)}")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    # ================= 2. è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆä¿®å¤ç»´åº¦é—®é¢˜ï¼‰=================
    # --- âœ… æ ¸å¿ƒä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šæœ‰3ä¸ªç±»åˆ«ï¼ˆ0,1,2ï¼‰ï¼Œå³ä½¿æŸäº›ç±»åˆ«æœªå‡ºç° ---
    num_classes = 3  # å¿…é¡»ä¸æ¨¡å‹è¾“å‡ºç»´åº¦ä¸€è‡´
    unique_actions, action_counts = np.unique(actions, return_counts=True)
    print(f"ğŸ“Š åŸå§‹åŠ¨ä½œåˆ†å¸ƒ: {dict(zip(unique_actions, action_counts))}")
    
    # åˆå§‹åŒ–æ‰€æœ‰ç±»åˆ«çš„æƒé‡ä¸º1.0
    class_weights = np.ones(num_classes)
    total_samples = len(actions)
    
    for idx, act in enumerate(unique_actions):
        # è½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•
        act = int(act)
        # åé¢‘ç‡æƒé‡
        weight = total_samples / (num_classes * action_counts[idx])
        class_weights[act] = weight
        
        # --- âœ… æ”¾å¤§åœæ­¢åŠ¨ä½œï¼ˆå‡è®¾åŠ¨ä½œ2æ˜¯åœæ­¢ï¼‰çš„æƒé‡ ---
        if act == 2:
            class_weights[act] *= 10.0
            print(f"ğŸ”¥ åŠ¨ä½œ {act} ('åœæ­¢') çš„æƒé‡è¢«æ”¾å¤§è‡³: {class_weights[act]:.2f}")
    
    # è½¬æ¢ä¸º Tensor
    class_weights = torch.FloatTensor(class_weights)
    print(f"âš–ï¸  æœ€ç»ˆç±»åˆ«æƒé‡ï¼ˆæ‰€æœ‰3ç±»ï¼‰: {class_weights.numpy()}")  # åº”è¾“å‡º3ä¸ªå€¼

    # ================= 3. æ•°æ®é›†å‡†å¤‡ =================
    states_tensor = torch.FloatTensor(states)
    actions_tensor = torch.LongTensor(actions)
    dataset = TensorDataset(states_tensor, actions_tensor)
    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

    # ================= 4. æ¨¡å‹ä¸ä¼˜åŒ–å™¨ =================
    model = PuzzleNet(input_dim=24, hidden_dim=128, output_dim=3)
    # --- âœ… å…³é”®ï¼šæƒé‡ç»´åº¦ç°åœ¨ä¸è¾“å‡ºå±‚åŒ¹é… ---
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    optimizer = optim.Adam(model.parameters(), lr=1e-3)

    # ================= 5. è®­ç»ƒå¾ªç¯ =================
    model.train()
    epochs = 100
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    for epoch in range(epochs):
        total_loss = 0
        for batch_states, batch_actions in dataloader:
            optimizer.zero_grad()
            logits = model(batch_states)
            loss = criterion(logits, batch_actions)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        if (epoch+1) % 20 == 0:
            avg_loss = total_loss / len(dataloader)
            print(f"Epoch [{epoch+1}/{epochs}], å¹³å‡ Loss: {avg_loss:.4f}")
    
    # ================= 6. ä¿å­˜æ¨¡å‹ =================
    model_dir = os.path.join(CURRENT_DIR, "data", "models")
    os.makedirs(model_dir, exist_ok=True)
    model_path = os.path.join(model_dir, "bc_model_weighted.pth")
    torch.save(model.state_dict(), model_path)
    print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼å·²ä¿å­˜è‡³: {model_path}")

if __name__ == "__main__":
    train_bc_model()