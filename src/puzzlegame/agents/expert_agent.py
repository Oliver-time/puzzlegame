# src/puzzlegame/agents/expert_agent.py

import numpy as np
import random
from puzzlegame.core.environment import PuzzleGame

class ExpertAgent:
    def __init__(self, env):
        self.env = env
        print(f"ğŸ® ä¸“å®¶æ•™å¸ˆå·²åŠ è½½ã€‚")

    def get_action(self, obs):
        current_pos = obs['current_pos']
        target_pos = obs['target_pos']

        if current_pos < target_pos:
            return 1  # å³ç§»
        elif current_pos > target_pos:
            return 0  # å·¦ç§»
        else:
            return 2  # ç¡®è®¤

    def generate_demonstrations(self, num_episodes=100, save_path=None):
        """
        ç”Ÿæˆæ¼”ç¤ºæ•°æ®ã€‚
        :param num_episodes: ç”Ÿæˆå¤šå°‘å±€
        :param save_path: ä¿å­˜è·¯å¾„ (ä¾‹å¦‚: "../data/raw/expert_data.npz")
        :return: æ•°æ®å­—å…¸
        """
        # ç”¨äºå­˜å‚¨æ‰€æœ‰çŠ¶æ€å’ŒåŠ¨ä½œ
        all_states = []
        all_actions = []
        
        # åŠ¨ä½œè®¡æ•°å™¨
        action_counts = {0: 0, 1: 0, 2: 0}  # 0:å·¦ç§», 1:å³ç§», 2:ç¡®è®¤

        for episode in range(num_episodes):
            obs = self.env.reset()
            done = False

            while not done:
                action = self.get_action(obs)
                
                # æ›´æ–°åŠ¨ä½œè®¡æ•°
                action_counts[action] += 1
                
                # è·å–ä¸‹ä¸€ä¸ªçŠ¶æ€ (ä¸ºäº†æ„å»ºçŠ¶æ€å‘é‡)
                next_obs, reward, done, _ = self.env.step(action)
                
                # --- æ„å»ºçŠ¶æ€å‘é‡ (ä¸ä¹‹å‰ä¿æŒä¸€è‡´) ---
                background = obs['background']
                puzzle = obs['puzzle']
                pos_feature = np.array([obs['current_pos']])
                
                state_vec = np.concatenate([
                    background / 100.0,
                    puzzle / 100.0,
                    pos_feature / self.env.n
                ])
                
                # å­˜å…¥åˆ—è¡¨
                all_states.append(state_vec)
                all_actions.append(action)
                
                obs = next_obs

        # è½¬æ¢ä¸º NumPy æ•°ç»„
        all_states = np.array(all_states)
        all_actions = np.array(all_actions)

        # --- æ˜¾ç¤ºåŠ¨ä½œç»Ÿè®¡ ---
        total_actions = len(all_actions)
        print(f"\nğŸ“Š åŠ¨ä½œç»Ÿè®¡:")
        print(f"  å·¦ç§» (åŠ¨ä½œ0): {action_counts[0]} æ¬¡")
        print(f"  å³ç§» (åŠ¨ä½œ1): {action_counts[1]} æ¬¡")
        print(f"  ç¡®è®¤ (åŠ¨ä½œ2): {action_counts[2]} æ¬¡")
        print(f"  æ€»è®¡: {total_actions} æ¬¡")

        # --- ä¿å­˜æ•°æ® ---
        if save_path:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            import os
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            np.savez(save_path, states=all_states, actions=all_actions)
            print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³: {save_path}")
            print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: çŠ¶æ€ {all_states.shape}, åŠ¨ä½œ {all_actions.shape}")

        return all_states, all_actions