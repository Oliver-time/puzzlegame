# src/puzzlegame/algorithms/train_bc.py

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import os
from torch.utils.data import DataLoader, TensorDataset
from puzzlegame.algorithms.behavioral_cloning import PuzzleNet

def train_bc_betterstop():
    # ================= 1. åŠ è½½æ•°æ® =================
    data_path = "data/raw/expert_demos.npz"
    data = np.load(data_path)
    states = data['states']  # å½¢çŠ¶: (N, 24)
    actions = data['actions'] # å½¢çŠ¶: (N,)
    
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œæ€»æ ·æœ¬æ•°: {len(states)}")
    
    # ================= 2. è®¡ç®—ç±»åˆ«æƒé‡ (æ ¸å¿ƒä¿®æ”¹ç‚¹) =================
    # ç»Ÿè®¡æ¯ä¸ªåŠ¨ä½œå‡ºç°çš„æ¬¡æ•°
    unique_actions, action_counts = np.unique(actions, return_counts=True)
    print(f"ğŸ“Š åŠ¨ä½œåˆ†å¸ƒ: {dict(zip(unique_actions, action_counts))}")
    
    # æ–¹æ³•ï¼šæƒé‡ä¸é¢‘ç‡æˆåæ¯”ï¼Œå¹¶å¯¹â€œåœæ­¢â€åŠ¨ä½œï¼ˆå‡è®¾æ˜¯2ï¼‰è¿›è¡Œé¢å¤–æ”¾å¤§
    # å…¬å¼: weight = total_samples / (n_classes * samples_per_class)
    # ä½†æˆ‘ä»¬æ‰‹åŠ¨å¹²é¢„ï¼Œç»™åœæ­¢åŠ¨ä½œæ›´å¤§çš„æƒé‡
    class_weights = np.ones(len(unique_actions))
    
    total_samples = len(actions)
    for idx, act in enumerate(unique_actions):
        # åŸºç¡€æƒé‡ï¼šé¢‘ç‡è¶Šä½ï¼Œæƒé‡è¶Šé«˜
        base_weight = total_samples / (len(unique_actions) * action_counts[idx])
        class_weights[idx] = base_weight
        
        # --- âœ… é‡ç‚¹ï¼šé’ˆå¯¹â€œåœæ­¢â€åŠ¨ä½œï¼ˆåŠ¨ä½œ2ï¼‰è¿›è¡Œæš´åŠ›æ”¾å¤§ ---
        if act == 2: # å‡è®¾ 2 æ˜¯åœæ­¢/ç¡®è®¤åŠ¨ä½œ
            class_weights[idx] *= 10.0 # æ”¾å¤§10å€ï¼è®©æ¨¡å‹æåº¦å®³æ€•é¢„æµ‹é”™åœæ­¢å¸§
            print(f"ğŸ”¥ åŠ¨ä½œ {act} (åœæ­¢) çš„æƒé‡è¢«æ”¾å¤§è‡³: {class_weights[idx]:.2f}")
    
    # è½¬æ¢ä¸º Tensor
    class_weights = torch.FloatTensor(class_weights)
    print(f"âš–ï¸  æœ€ç»ˆç±»åˆ«æƒé‡: {class_weights.numpy()}")

    # ================= 3. æ„å»º DataLoader =================
    dataset = TensorDataset(
        torch.FloatTensor(states),
        torch.LongTensor(actions)
    )
    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

    # ================= 4. åˆå§‹åŒ–æ¨¡å‹ä¸ä¼˜åŒ–å™¨ =================
    model = PuzzleNet(input_dim=24, hidden_dim=128, output_dim=3)
    # --- âœ… å…³é”®ï¼šå°†æƒé‡ä¼ å…¥ CrossEntropyLoss ---
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    optimizer = optim.Adam(model.parameters(), lr=1e-3)

    # ================= 5. è®­ç»ƒå¾ªç¯ =================
    model.train()
    epochs = 100
    
    for epoch in range(epochs):
        total_loss = 0
        for batch_states, batch_actions in dataloader:
            optimizer.zero_grad()
            logits = model(batch_states)
            loss = criterion(logits, batch_actions)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        # æ‰“å°æŸå¤±
        if (epoch+1) % 20 == 0:
            print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(dataloader):.4f}")
    
    # ================= 6. ä¿å­˜æ¨¡å‹ =================
    model_dir = "data/models"
    os.makedirs(model_dir, exist_ok=True)
    torch.save(model.state_dict(), f"{model_dir}/bc_model_weighted.pth")
    print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆå¹¶ä¿å­˜: {model_dir}/bc_model_weighted.pth")

if __name__ == "__main__":
    train_bc_betterstop()
