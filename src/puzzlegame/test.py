# src/puzzlegame/test.py

import os
import torch
import numpy as np

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))

from puzzlegame.core.environment import PuzzleGame
from puzzlegame.algorithms.behavioral_cloning import PuzzleNet

def process_state(raw_state):
    # ... (ä¿æŒä¹‹å‰çš„å¤„ç†é€»è¾‘ä¸å˜ï¼Œç¡®ä¿ç»´åº¦ä¸º24) ...
    processed = []
    if isinstance(raw_state, dict):
        for value in raw_state.values():
            if isinstance(value, (list, np.ndarray)):
                processed.extend(value)
            else:
                processed.append(value)
    elif isinstance(raw_state, (list, np.ndarray)):
        processed = list(raw_state)
    else:
        processed = [raw_state]

    processed = np.array(processed)
    flat_state = processed.ravel()
    
    # å‡è®¾è®­ç»ƒç»´åº¦æ˜¯24
    expected_dim = 24
    if flat_state.size > expected_dim:
        return flat_state[:expected_dim]
    elif flat_state.size < expected_dim:
        padded = np.zeros(expected_dim)
        padded[:flat_state.size] = flat_state
        return padded
    return flat_state

def display_game_info(env, current_pos, target_pos):
    """æ˜¾ç¤ºæ¸¸æˆä»»åŠ¡çš„å…·ä½“æƒ…å†µ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ä»»åŠ¡è¯¦æƒ…:")
    print(f"  æ‹¼å›¾æ€»é•¿åº¦ (n): {env.n}")
    print(f"  æ‹¼å›¾å—é•¿åº¦ (m): {env.m}")
    print(f"  å½“å‰æ‹¼å›¾ä½ç½®: {current_pos}")
    print(f"  ç›®æ ‡ä½ç½®: {target_pos}")
    print(f"  è·ç¦»ç›®æ ‡: {abs(current_pos - target_pos)} æ­¥")
    print(f"  æ‹¼å›¾å—å€¼: {env.puzzle_piece}")
    
    # æ˜¾ç¤ºç®€åŒ–çš„æ¸¸æˆçŠ¶æ€
    display = []
    for i in range(env.n):
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡åŒºåŸŸ
        is_target = target_pos <= i < target_pos + env.m
        # æ£€æŸ¥å½“å‰æ˜¯å¦æœ‰æ‹¼å›¾å—
        has_puzzle = current_pos <= i < current_pos + env.m
        
        if has_puzzle and is_target:
            display.append('[ğŸ¯]')  # æ­£ç¡®ä½ç½®
        elif has_puzzle:
            display.append('[ğŸ§©]')  # æ‹¼å›¾å—
        elif is_target:
            display.append('[â¬œ]')  # ç›®æ ‡ç¼ºå£
        else:
            display.append(' . ')   # ç©ºä½ç½®
            
    print(f"\n  æ¸¸æˆçŠ¶æ€:")
    print(f"  {' '.join(display[:min(30, len(display))])}")
    if env.n > 30:
        print(f"  ... (å…±{env.n}ä¸ªä½ç½®)")
    print(f"{'='*60}\n")

def main():
    # --- âœ… ä¿®æ”¹ï¼šæŒ‡å‘æ–°è®­ç»ƒçš„åŠ æƒæ¨¡å‹ ---
    model_path = os.path.join(CURRENT_DIR, "data", "models", "bc_model_weighted.pth")
    
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        print("è¯·å…ˆè¿è¡Œ train_bc.py ç”Ÿæˆæ¨¡å‹")
        return

    model = PuzzleNet(input_dim=24, hidden_dim=128, output_dim=3)
    model.load_state_dict(torch.load(model_path))
    model.eval()
    print(f"âœ… åŠ è½½åŠ æƒæ¨¡å‹æˆåŠŸ: {model_path}")

    env = PuzzleGame(n=20, m=3)
    raw_state = env.reset() 
    
    # è·å–åˆå§‹çŠ¶æ€ä¿¡æ¯
    if isinstance(raw_state, dict):
        current_pos = raw_state.get('current_pos', 0)
        target_pos = raw_state.get('target_pos', 0)
    else:
        current_pos = 0
        target_pos = env.target_pos if hasattr(env, 'target_pos') else 0
    
    print(f"ğŸ® å¼€å§‹æ¸¸æˆæµ‹è¯•...")
    print(f"ğŸ”§ ç¯å¢ƒè®¾ç½®: n={env.n}, m={env.m}")
    print(f"ğŸ¯ ä»»åŠ¡ç›®æ ‡: å°†æ‹¼å›¾å—ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½® {target_pos}")
    
    # æ˜¾ç¤ºåˆå§‹ä»»åŠ¡æƒ…å†µ
    display_game_info(env, current_pos, target_pos)

    done = False
    step = 0
    total_reward = 0
    
    while not done:
        step += 1
        processed_state = process_state(raw_state)
        state_tensor = torch.FloatTensor(processed_state).unsqueeze(0)
        
        with torch.no_grad():
            logits = model(state_tensor)
            action_idx = torch.argmax(logits, dim=1).item()
            action_probs = torch.softmax(logits, dim=1)[0].numpy()
        
        # åŠ¨ä½œæ˜ å°„
        action_map = {0: "â† å·¦ç§»", 1: "â†’ å³ç§»", 2: "âœ“ ç¡®è®¤æ”¾ç½®"}
        action_name = action_map.get(action_idx, f"æœªçŸ¥åŠ¨ä½œ {action_idx}")
        
        # æ‰§è¡Œç¯å¢ƒæ­¥è¿›
        result = env.step(action_idx)
        if len(result) == 4:
            raw_state, reward, done, info = result
        elif len(result) == 5:
            raw_state, reward, done, _, info = result
        
        total_reward += reward
        
        # è·å–å½“å‰ä½ç½®
        if isinstance(raw_state, dict):
            current_pos = raw_state.get('current_pos', current_pos)
            target_pos = raw_state.get('target_pos', target_pos)
        
        print(f"\nğŸ“‹ Step {step}:")
        print(f"  ğŸ¤– æ¨¡å‹å†³ç­–: {action_name} (ç½®ä¿¡åº¦: {action_probs[action_idx]:.3f})")
        print(f"  ğŸ† å³æ—¶å¥–åŠ±: {reward:.1f}")
        print(f"  ğŸ“ å½“å‰ä½ç½®: {current_pos}")
        print(f"  ğŸ¯ ç›®æ ‡ä½ç½®: {target_pos}")
        print(f"  ğŸ“ å‰©ä½™è·ç¦»: {abs(current_pos - target_pos)}")
        
        # æ¯5æ­¥æ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†çŠ¶æ€
        if step % 5 == 0 or done:
            display_game_info(env, current_pos, target_pos)
        
        # æ­¥æ•°ä¸Šé™è®¾ä¸º50
        if step >= 50:
            print(f"\nâš ï¸  è¶…è¿‡æœ€å¤§æ­¥æ•°é™åˆ¶ï¼ˆ50æ­¥ï¼‰")
            print(f"ğŸ“Š ç»Ÿè®¡: æ€»æ­¥æ•°={step}, æ€»å¥–åŠ±={total_reward}")
            done = True
            break

    # æœ€ç»ˆç»“æœ
    print(f"\n{'='*60}")
    print(f"ğŸ¯ ä»»åŠ¡å®Œæˆæƒ…å†µ:")
    if reward > 0:
        print(f"  âœ… æˆåŠŸï¼æ‹¼å›¾å—å·²æ­£ç¡®æ”¾ç½®åˆ°ç›®æ ‡ä½ç½®")
        print(f"  ğŸ‰ æœ€ç»ˆå¥–åŠ±: {reward}")
    else:
        print(f"  âŒ å¤±è´¥ï¼æœªèƒ½åœ¨ç›®æ ‡ä½ç½®æ”¾ç½®æ‹¼å›¾å—")
        print(f"  ğŸ“ å½“å‰ä½ç½®: {current_pos}, ç›®æ ‡ä½ç½®: {target_pos}")
    
    print(f"  ğŸ“Š ç»Ÿè®¡:")
    print(f"    æ€»æ­¥æ•°: {step}")
    print(f"    æ€»å¥–åŠ±: {total_reward}")
    print(f"    æœ€ç»ˆä½ç½®: {current_pos}")
    print(f"    ç›®æ ‡ä½ç½®: {target_pos}")
    print(f"    å‡†ç¡®åº¦: {'æ­£ç¡®' if current_pos == target_pos else 'é”™è¯¯'}")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()