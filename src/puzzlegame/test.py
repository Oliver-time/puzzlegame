# src/puzzlegame/test.py

import os
import torch
import numpy as np

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨çš„ç›®å½• (å³ src/puzzlegame/)
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))

from puzzlegame.core.environment import PuzzleGame
from puzzlegame.algorithms.behavioral_cloning import PuzzleNet

def process_state(raw_state):
    """
    å°†ç¯å¢ƒè¿”å›çš„çŠ¶æ€ï¼ˆå¯èƒ½æ˜¯å­—å…¸æˆ–æ•°ç»„ï¼‰è½¬æ¢ä¸ºä¸€ç»´ numpy æ•°ç»„
    å¹¶å¼ºåˆ¶è°ƒæ•´ç»´åº¦ä¸º 24 (ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´)
    """
    processed = []
    
    if isinstance(raw_state, dict):
        # å¦‚æœçŠ¶æ€æ˜¯å­—å…¸ï¼Œæå–æ‰€æœ‰å€¼å¹¶å±•å¹³
        for value in raw_state.values():
            if isinstance(value, (list, np.ndarray)):
                processed.extend(value)
            else:
                processed.append(value)
    elif isinstance(raw_state, (list, np.ndarray)):
        # å¦‚æœæœ¬èº«å°±æ˜¯åˆ—è¡¨æˆ–æ•°ç»„
        processed = list(raw_state)
    else:
        # å…œåº•
        processed = [raw_state]

    # è½¬æ¢ä¸º numpy æ•°é˜µ
    processed = np.array(processed)
    
    # --- è·å–å®é™…çš„ç‰¹å¾æ•°é‡ ---
    flat_state = processed.ravel()
    current_dim = flat_state.size 
    expected_dim = 24

    # --- å¼ºåˆ¶ç»´åº¦å¯¹é½ ---
    if current_dim == expected_dim:
        return flat_state
    elif current_dim > expected_dim:
        print(f"âš ï¸  çŠ¶æ€ç»´åº¦è¿‡å¤š ({current_dim})ï¼Œå·²è‡ªåŠ¨æˆªæ–­ä¸º {expected_dim}")
        return flat_state[:expected_dim]
    else:
        print(f"âš ï¸  çŠ¶æ€ç»´åº¦ä¸è¶³ ({current_dim})ï¼Œå·²è‡ªåŠ¨å¡«å……0è‡³ {expected_dim}")
        padded = np.zeros(expected_dim)
        padded[:current_dim] = flat_state
        return padded

def main():
    # 1. æ„å»ºæ¨¡å‹è·¯å¾„å¹¶åŠ è½½
    model_path = os.path.join(CURRENT_DIR, "data", "models", "bc_model.pth")
    
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        return

    model = PuzzleNet(input_dim=24, hidden_dim=128, output_dim=3)
    model.load_state_dict(torch.load(model_path))
    model.eval()
    print(f"âœ… åŠ è½½æ¨¡å‹æˆåŠŸ: {model_path}")

    # 2. åˆ›å»ºç¯å¢ƒ
    env = PuzzleGame(n=20, m=3)
    
    # é‡ç½®ç¯å¢ƒ
    raw_state = env.reset() 
    print(f"ğŸ® å¼€å§‹æ¸¸æˆæµ‹è¯•... ç›®æ ‡: ç§»åŠ¨ {env.m} ä¸ªæ–¹å—åˆ°å³ä¾§")

    # 3. è¿è¡Œæ¸¸æˆ
    done = False
    step = 0
    
    while not done:
        step += 1
        
        # --- é¢„å¤„ç†çŠ¶æ€ ---
        processed_state = process_state(raw_state)
        
        # è½¬æ¢ä¸º Tensor
        state_tensor = torch.FloatTensor(processed_state).unsqueeze(0)
        
        # æ¨¡å‹é¢„æµ‹
        with torch.no_grad():
            logits = model(state_tensor)
            action_idx = torch.argmax(logits, dim=1).item()
        
        # --- ä¿®å¤ï¼šç¯å¢ƒåªè¿”å›äº† 4 ä¸ªå€¼ ---
        # å¸¸è§çš„è¿”å›æ ¼å¼: (next_state, reward, done, info)
        result = env.step(action_idx)
        
        # æ ¹æ®è¿”å›å€¼çš„æ•°é‡è¿›è¡Œè§£åŒ…
        if len(result) == 4:
            raw_state, reward, done, info = result
        elif len(result) == 5:
            # å…¼å®¹æ–°ç‰ˆ Gym æ ¼å¼ (next_state, reward, terminated, truncated, info)
            raw_state, reward, done, _, info = result
        else:
            # å¦‚æœæ ¼å¼å¼‚å¸¸ï¼Œç›´æ¥æŠ¥é”™
            raise ValueError(f"env.step() è¿”å›äº† {len(result)} ä¸ªå€¼ï¼Œæ— æ³•è§£æ: {result}")

        print(f"Step {step}: åŠ¨ä½œ={action_idx}, å¥–åŠ±={reward}, å®Œæˆ={done}")
        
        if step > 100:
            print("âš ï¸  è¶…è¿‡æœ€å¤§æ­¥æ•°ï¼Œæ¸¸æˆç»“æŸ")
            break

    if done and reward > 0:
        print("ğŸ‰ æ¨¡å‹æˆåŠŸå®Œæˆäº†ä»»åŠ¡ï¼")
    else:
        print("âŒ æ¨¡å‹æœªèƒ½å®Œæˆä»»åŠ¡")

if __name__ == "__main__":
    main()